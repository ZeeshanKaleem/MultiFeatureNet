{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie5uLDH4uzAp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671596486796,"user_tz":-300,"elapsed":1474,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"}},"outputId":"cb79f31b-67c4-45bf-90d9-944138924e10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 14840, done.\u001b[K\n","remote: Counting objects: 100% (185/185), done.\u001b[K\n","remote: Compressing objects: 100% (75/75), done.\u001b[K\n","remote: Total 14840 (delta 127), reused 154 (delta 110), pack-reused 14655\u001b[K\n","Receiving objects: 100% (14840/14840), 13.88 MiB | 12.90 MiB/s, done.\n","Resolving deltas: 100% (10210/10210), done.\n","/content/yolov5\n","HEAD is now at fbe67e4 Fix `OMP_NUM_THREADS=1` for macOS (#8624)\n"]}],"source":["# clone YOLOv5 repository\n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","!git reset --hard fbe67e465375231474a2ad80a4389efc77ecff99"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wbvMlHd_QwMG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671596705568,"user_tz":-300,"elapsed":9584,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"}},"outputId":"68b9f3fd-48d5-419f-fe34-42e91061121e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |▏                               | 10 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 92 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 112 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 122 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 133 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 143 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 153 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 163 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 174 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 184 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 194 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 204 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 215 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 225 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 235 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 245 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 256 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 266 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 276 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 286 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 296 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 307 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 317 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 327 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 337 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 348 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 358 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 368 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 378 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 389 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 399 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 409 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 419 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 430 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 440 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 450 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 460 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 471 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 481 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 491 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 501 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 512 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 522 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 532 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 542 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 552 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 563 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 573 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 583 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 593 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 604 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 614 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 624 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 634 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 645 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 655 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 665 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 675 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 686 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 696 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 706 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 716 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 727 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 737 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 747 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 757 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 768 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 778 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 788 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 798 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 808 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 819 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 829 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 839 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 849 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 860 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 870 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 880 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 890 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 901 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 911 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 921 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 931 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 942 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 952 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 962 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 972 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 983 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 993 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.0 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.0 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.0 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.0 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.3 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.5 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.6 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 14.4 MB/s \n","\u001b[?25hSetup complete. Using torch 1.13.0+cu116 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"]}],"source":["# install dependencies as necessary\n","!pip install -qr requirements.txt  # install dependencies (ignore errors)\n","import torch\n","\n","from IPython.display import Image, clear_output  # to display images\n","from utils.downloads import attempt_download  # to download models/datasets\n","\n","# clear_output()\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Knxi2ncxWffW","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1671596747629,"user_tz":-300,"elapsed":42068,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"}},"outputId":"f214f1cd-4c1a-4379-d21f-632a2250a0c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting roboflow\n","  Downloading roboflow-0.2.21-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.10)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (7.1.2)\n","Collecting certifi==2021.5.30\n","  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 22.2 MB/s \n","\u001b[?25hCollecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.8.2)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.64.1)\n","Collecting cycler==0.10.0\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting chardet==4.0.0\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[K     |████████████████████████████████| 178 kB 63.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.23.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (6.0)\n","Collecting urllib3==1.26.6\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 70.6 MB/s \n","\u001b[?25hCollecting python-dotenv\n","  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.15.0)\n","Collecting requests-toolbelt\n","  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: glob2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.7)\n","Requirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.6.0.66)\n","Collecting pyparsing==2.4.7\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.21.6)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.4.4)\n","Collecting requests\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->roboflow) (2.1.1)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=521a3fb0301e906310fedcd271b36dc67fabdb3a771fa2334c3a5eada72307b6\n","  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n","Successfully built wget\n","Installing collected packages: urllib3, certifi, requests, pyparsing, cycler, wget, requests-toolbelt, python-dotenv, chardet, roboflow\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2022.12.7\n","    Uninstalling certifi-2022.12.7:\n","      Successfully uninstalled certifi-2022.12.7\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.0.9\n","    Uninstalling pyparsing-3.0.9:\n","      Successfully uninstalled pyparsing-3.0.9\n","  Attempting uninstall: cycler\n","    Found existing installation: cycler 0.11.0\n","    Uninstalling cycler-0.11.0:\n","      Successfully uninstalled cycler-0.11.0\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 3.0.4\n","    Uninstalling chardet-3.0.4:\n","      Successfully uninstalled chardet-3.0.4\n","Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 pyparsing-2.4.7 python-dotenv-0.21.0 requests-2.28.1 requests-toolbelt-0.10.1 roboflow-0.2.21 urllib3-1.26.6 wget-3.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","chardet","cycler","pyparsing","requests","urllib3"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","Downloading Dataset Version Zip in Uav-7 to yolov5pytorch: 100% [86760366 / 86760366] bytes\n"]},{"output_type":"stream","name":"stderr","text":["Extracting Dataset Version Zip to Uav-7 in yolov5pytorch:: 100%|██████████| 10042/10042 [00:02<00:00, 3943.16it/s]\n"]}],"source":["#follow the link below to get your download code from from Roboflow\n","!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"fXNvqJubpdjp1mf8IS6s\")\n","project = rf.workspace(\"detection-axsgy\").project(\"uav-ce0zg\")\n","dataset = project.version(7).download(\"yolov5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ug_PhK1oqwQA"},"outputs":[],"source":["%cd /content/yolov5\n","#after following the link above, recieve python code with these fields filled in\n","#from roboflow import Roboflow\n","#rf = Roboflow(api_key=\"YOUR API KEY HERE\")\n","#project = rf.workspace().project(\"YOUR PROJECT\")\n","#dataset = project.version(\"YOUR VERSION\").download(\"yolov5\")\n","# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n","%cat {dataset.location}/data.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dOPn9wjOAwwK"},"outputs":[],"source":["# define number of classes based on YAML\n","import yaml\n","with open(dataset.location + \"/data.yaml\", 'r') as stream:\n","    num_classes = str(yaml.safe_load(stream)['nc'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Rvt5wilnDyX"},"outputs":[],"source":["#this is the model configuration we will use for our tutorial \n","%cat //content/yolov5/models/yolov5s.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t14hhyqdmw6O"},"outputs":[],"source":["#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uDxebz13RdRA"},"outputs":[],"source":["%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n","\n","# parameters\n","nc: {num_classes}  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","#Anchor boxes are a set of predefined bounding boxes of a certain height and width. These boxes are defined to capture the scale and \n","#aspect ratio of specific object classes you want to detect and are typically chosen based on object sizes in your training datasets\n","# anchors\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  #The focus layer was created to reduce layers, parameters, FLOPS, and CUDA memory and improve forward and backward speed while minimizing the impact of mAP\n","  ## ch_in, ch_out, kernel, stride, padding, groups\n","  [[-1, 1, Focus, [256, 3]],  # 0-P1/2\n","   # Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)\n","   [-1, 1, Conv, [256, 3, 2]],  # 1-P2/4\n","   #It employs a CSPNet strategy to partition the feature map of the base layer into two parts \n","   #and then merges them through a cross-stage hierarchy. The use of a split and merge strategy allows for more gradient flow through the network.\n","   # ch_in, ch_out, number, shortcut, groups, expansion\n","   [-1, 3, BottleneckCSP, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, BottleneckCSP, [256]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 5-P4/16\n","   [-1, 9, BottleneckCSP, [512]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 7-P5/32\n","   #Spatial Pyramid Pooling (SPP) is a pooling layer that removes the fixed-size constraint of the network, i.e. a CNN does not require a fixed-size input image\n","   [-1, 1, SPP, [256, [5, 9, 13]]],\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","  [[-1, 1, Conv, [128, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, BottleneckCSP, [128, False]],  # 13\n"," #nn.Upsample(scale_factor=2, mode='nearest')\n","   [-1, 1, Conv, [128, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, BottleneckCSP, [128, False]],  # 17 (P3/medium)\n","\n","   [-1, 1, Conv, [128, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, BottleneckCSP, [128, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [128, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, BottleneckCSP, [128, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1NcFxRcFdJ_O"},"outputs":[],"source":["# train yolov5s on custom data for 100 epochs\n","# time its performance\n","%%time\n","%cd /content/yolov5/\n","!python train.py --img 416 --batch 32 --epochs 200 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name FeatureNetsmall_results  --cache"]},{"cell_type":"markdown","metadata":{"id":"kJVs_4zEeVbF"},"source":["# Evaluate Custom YOLOv5 Detector Performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bOy5KI2ncnWd"},"outputs":[],"source":["# Start tensorboard\n","# Launch after you have started training\n","# logs save in the folder \"runs\"\n","%load_ext tensorboard\n","%tensorboard --logdir runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C60XAsyv6OPe"},"outputs":[],"source":["# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n","from utils.plots import plot_results  # plot results.txt as results.png\n","Image(filename='/content/yolov5/runs/train/FeatureNetsmall_results/results.png', width=1000)  # view results.png"]},{"cell_type":"markdown","metadata":{"id":"N3qM6T0W53gh"},"source":["#Run Inference  With Trained Weights\n","Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIEwt5YLeQ7P"},"outputs":[],"source":["# trained weights are saved by default in our weights folder\n","%ls runs/\n","%ls runs/train/FeatureNetsmall_results/weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9nmZZnWOgJ2S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671601538365,"user_tz":-300,"elapsed":63281,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"}},"outputId":"20b448f1-a92d-4e31-9e54-1991c235d1fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n","\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/mfnets.pt'], source=/content/yolov5/Uav-7/test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=True, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage0_Focus_features.png... (32/128)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage1_Conv_features.png... (32/128)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage2_BottleneckCSP_features.png... (32/64)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage3_Conv_features.png... (32/128)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage4_BottleneckCSP_features.png... (32/128)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage5_Conv_features.png... (32/128)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage6_BottleneckCSP_features.png... (32/256)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage7_Conv_features.png... (32/128)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage8_SPP_features.png... (32/128)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage9_BottleneckCSP_features.png... (32/512)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage10_Conv_features.png... (32/64)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage11_Upsample_features.png... (32/64)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage12_Concat_features.png... (32/320)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage13_BottleneckCSP_features.png... (32/64)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage14_Conv_features.png... (32/64)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage15_Upsample_features.png... (32/64)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage16_Concat_features.png... (32/192)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage17_BottleneckCSP_features.png... (32/64)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage18_Conv_features.png... (32/64)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage19_Concat_features.png... (32/128)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage20_BottleneckCSP_features.png... (32/64)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage21_Conv_features.png... (32/64)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage22_Concat_features.png... (32/128)\n","Saving runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage23_BottleneckCSP_features.png... (32/64)\n","image 1/214 /content/yolov5/Uav-7/test/images/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6.jpg: 416x416 1 drone, Done. (30.986s)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage0_Focus_features.png... (32/128)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage1_Conv_features.png... (32/128)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage2_BottleneckCSP_features.png... (32/64)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage3_Conv_features.png... (32/128)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage4_BottleneckCSP_features.png... (32/128)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage5_Conv_features.png... (32/128)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage6_BottleneckCSP_features.png... (32/256)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage7_Conv_features.png... (32/128)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage8_SPP_features.png... (32/128)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage9_BottleneckCSP_features.png... (32/512)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage10_Conv_features.png... (32/64)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage11_Upsample_features.png... (32/64)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage12_Concat_features.png... (32/320)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage13_BottleneckCSP_features.png... (32/64)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage14_Conv_features.png... (32/64)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage15_Upsample_features.png... (32/64)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage16_Concat_features.png... (32/192)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage17_BottleneckCSP_features.png... (32/64)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage18_Conv_features.png... (32/64)\n","Saving runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage19_Concat_features.png... (32/128)\n","Traceback (most recent call last):\n","  File \"detect.py\", line 256, in <module>\n","    main(opt)\n","  File \"detect.py\", line 251, in main\n","    run(**vars(opt))\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"detect.py\", line 122, in run\n","    pred = model(im, augment=augment, visualize=visualize)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/yolov5/models/common.py\", line 455, in forward\n","    y = self.model(im, augment=augment, visualize=visualize)[0]\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/yolov5/models/yolo.py\", line 135, in forward\n","    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n","  File \"/content/yolov5/models/yolo.py\", line 161, in _forward_once\n","    feature_visualization(x, m.type, m.i, save_dir=visualize)\n","  File \"/content/yolov5/utils/plots.py\", line 151, in feature_visualization\n","    plt.savefig(f, dpi=300, bbox_inches='tight')\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\", line 724, in savefig\n","    fig.canvas.draw_idle()   # need this if 'transparent=True' to reset colors\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/backend_bases.py\", line 1947, in draw_idle\n","    self.draw(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py\", line 393, in draw\n","    self.figure.draw(self.renderer)\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py\", line 38, in draw_wrapper\n","    return draw(artist, renderer, *args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/figure.py\", line 1735, in draw\n","    mimage._draw_list_compositing_images(\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\", line 137, in _draw_list_compositing_images\n","    a.draw(renderer)\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py\", line 38, in draw_wrapper\n","    return draw(artist, renderer, *args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\", line 2630, in draw\n","    mimage._draw_list_compositing_images(renderer, self, artists)\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\", line 137, in _draw_list_compositing_images\n","    a.draw(renderer)\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py\", line 38, in draw_wrapper\n","    return draw(artist, renderer, *args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\", line 625, in draw\n","    im, l, b, trans = self.make_image(\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\", line 914, in make_image\n","    return self._make_image(\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\", line 478, in _make_image\n","    A_resampled = _resample(self, A_scaled, out_shape, t)\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\", line 181, in _resample\n","    pos = np.array([[0, 0], [data.shape[1], data.shape[0]]])\n","KeyboardInterrupt\n","^C\n"]}],"source":["\n","%cd /content/yolov5/\n","!python detect.py --weights runs/train/FeatureNetsmall_results/weights/best.pt --img 416 --conf 0.4 --source /content/yolov5/Uav-7/test/images --visualize"]},{"cell_type":"code","source":["#### Visulize each layers feature map\n","#######Run this cell to know the whats inside every lare feature\n","#### stop it ur self after one image is done\n","## Print whole folder feature maps and save them\n","#!python detect.py --weights /content/yolov5/mfnets.pt --img 416 --conf 0.4 --source /content/yolov5/Uav-7/test/images --visualize\n","####### Only single image\n","!python detect.py --weights /content/yolov5/mfnets.pt --img 416 --conf 0.4 --source /content/yolov5/Uav-7/test/images/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77.jpg --visualize\n","                                               "],"metadata":{"id":"Rl889R_TOVq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/yolov5/\n","!python val.py --weights /content/yolov5/mfnets.pt --data {dataset.location}/data.yaml --iou 0.3 --img 416 --verbose --save-txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K9fme31I6iuk","executionInfo":{"status":"ok","timestamp":1671601402494,"user_tz":-300,"elapsed":16921,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"}},"outputId":"9f8636db-3e17-4df2-d5c2-6b1956b5cc39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n","\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/Uav-7/data.yaml, weights=['/content/yolov5/mfnets.pt'], batch_size=32, imgsz=416, conf_thres=0.001, iou_thres=0.3, task=val, device=, workers=8, single_cls=False, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:06<00:00,  2.01it/s]\n","                 all        415        876        378       44.5      0.909      0.877      0.893      0.899      0.488\n","                bird        415        587        493         75      0.867       0.84      0.853      0.853       0.37\n","               drone        415        289        264         14      0.951      0.913      0.932      0.946      0.605\n","Speed: 0.1ms pre-process, 3.8ms inference, 3.0ms NMS per image at shape (32, 3, 416, 416)\n","Results saved to \u001b[1mruns/val/exp49\u001b[0m\n","415 labels saved to runs/val/exp49/labels\n"]}]},{"cell_type":"code","source":["!python val.py --task study --weights /content/yolov5/mfnets.pt --data {dataset.location}/data.yaml --iou 0.3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TW_l5cj79CCQ","executionInfo":{"status":"ok","timestamp":1671601094899,"user_tz":-300,"elapsed":95325,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"}},"outputId":"686a7bce-a83e-4b18-c9d4-f28309c15263"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/Uav-7/data.yaml, weights=['/content/yolov5/mfnets.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.3, task=study, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n","\n","Running study_data_mfnets.txt --imgsz 256...\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:03<00:00,  3.82it/s]\n","                 all        415        876        346         50      0.892      0.826      0.857      0.837      0.471\n","                bird        415        587        423         88      0.828       0.72       0.77      0.719        0.3\n","               drone        415        289        269         12      0.956      0.931      0.943      0.955      0.642\n","Speed: 0.0ms pre-process, 1.6ms inference, 1.2ms NMS per image at shape (32, 3, 256, 256)\n","Results saved to \u001b[1mruns/val/exp38\u001b[0m\n","\n","Running study_data_mfnets.txt --imgsz 384...\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:04<00:00,  3.05it/s]\n","                 all        415        876        376         34      0.927      0.875        0.9        0.9      0.496\n","                bird        415        587        487         57      0.895       0.83      0.861      0.852      0.365\n","               drone        415        289        266         11      0.959       0.92      0.939      0.948      0.628\n","Speed: 0.1ms pre-process, 2.4ms inference, 1.6ms NMS per image at shape (32, 3, 384, 384)\n","Results saved to \u001b[1mruns/val/exp39\u001b[0m\n","\n","Running study_data_mfnets.txt --imgsz 512...\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:04<00:00,  3.23it/s]\n","                 all        415        876        384       64.5      0.878       0.88      0.879      0.897      0.441\n","                bird        415        587        513        111      0.822      0.874      0.847      0.868      0.375\n","               drone        415        289        256         18      0.934      0.887       0.91      0.926      0.507\n","Speed: 0.1ms pre-process, 3.2ms inference, 1.2ms NMS per image at shape (32, 3, 512, 512)\n","Results saved to \u001b[1mruns/val/exp40\u001b[0m\n","\n","Running study_data_mfnets.txt --imgsz 640...\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:04<00:00,  2.76it/s]\n","                 all        415        876        352       93.5        0.8       0.77       0.78      0.795      0.349\n","                bird        415        587        512        145      0.779      0.872      0.823      0.852       0.36\n","               drone        415        289        193         42      0.821      0.668      0.737      0.737      0.338\n","Speed: 0.2ms pre-process, 4.5ms inference, 1.2ms NMS per image at shape (32, 3, 640, 640)\n","Results saved to \u001b[1mruns/val/exp41\u001b[0m\n","\n","Running study_data_mfnets.txt --imgsz 768...\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:05<00:00,  2.36it/s]\n","                 all        415        876        319        130      0.693      0.661      0.666      0.651       0.27\n","                bird        415        587        504        190      0.727      0.859      0.787      0.819      0.331\n","               drone        415        289        134         69       0.66      0.463      0.544      0.483       0.21\n","Speed: 0.3ms pre-process, 5.8ms inference, 1.4ms NMS per image at shape (32, 3, 768, 768)\n","Results saved to \u001b[1mruns/val/exp42\u001b[0m\n","\n","Running study_data_mfnets.txt --imgsz 896...\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:06<00:00,  1.93it/s]\n","                 all        415        876        285        184      0.548      0.559       0.54      0.532      0.217\n","                bird        415        587        486        266      0.646      0.828      0.726      0.774        0.3\n","               drone        415        289         84        102      0.451      0.291      0.353      0.291      0.134\n","Speed: 0.3ms pre-process, 8.3ms inference, 1.4ms NMS per image at shape (32, 3, 896, 896)\n","Results saved to \u001b[1mruns/val/exp43\u001b[0m\n","\n","Running study_data_mfnets.txt --imgsz 1024...\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:07<00:00,  1.72it/s]\n","                 all        415        876        255        166      0.558      0.483      0.482      0.463      0.178\n","                bird        415        587        455        277      0.621      0.775       0.69      0.723      0.258\n","               drone        415        289         55         56      0.495       0.19      0.275      0.204     0.0974\n","Speed: 0.4ms pre-process, 10.2ms inference, 1.4ms NMS per image at shape (32, 3, 1024, 1024)\n","Results saved to \u001b[1mruns/val/exp44\u001b[0m\n","\n","Running study_data_mfnets.txt --imgsz 1152...\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:09<00:00,  1.38it/s]\n","                 all        415        876        216        108      0.657      0.401      0.446      0.409      0.151\n","                bird        415        587        392        195      0.668      0.668      0.668      0.653      0.226\n","               drone        415        289         39         21      0.646      0.135      0.223      0.165     0.0767\n","Speed: 1.0ms pre-process, 14.0ms inference, 1.5ms NMS per image at shape (32, 3, 1152, 1152)\n","Results saved to \u001b[1mruns/val/exp45\u001b[0m\n","\n","Running study_data_mfnets.txt --imgsz 1280...\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:10<00:00,  1.25it/s]\n","                 all        415        876        190        122      0.591      0.353      0.397      0.337      0.123\n","                bird        415        587        345        219      0.612      0.587      0.599      0.552      0.187\n","               drone        415        289         34         26      0.571      0.118      0.195      0.123     0.0582\n","Speed: 0.6ms pre-process, 16.8ms inference, 1.4ms NMS per image at shape (32, 3, 1280, 1280)\n","Results saved to \u001b[1mruns/val/exp46\u001b[0m\n","\n","Running study_data_mfnets.txt --imgsz 1408...\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:12<00:00,  1.05it/s]\n","                 all        415        876        158        103       0.59      0.293      0.351      0.282     0.0958\n","                bird        415        587        291        186       0.61      0.496      0.547      0.476      0.153\n","               drone        415        289         26         20       0.57       0.09      0.155     0.0871     0.0388\n","Speed: 0.8ms pre-process, 20.9ms inference, 1.3ms NMS per image at shape (32, 3, 1408, 1408)\n","Results saved to \u001b[1mruns/val/exp47\u001b[0m\n","\n","Running study_data_mfnets.txt --imgsz 1536...\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:13<00:00,  1.06s/it]\n","                 all        415        876        154        137      0.479      0.283      0.323      0.254      0.084\n","                bird        415        587        285        242      0.541      0.486      0.512      0.442      0.139\n","               drone        415        289         23         32      0.417     0.0796      0.134     0.0658     0.0293\n","Speed: 0.9ms pre-process, 23.3ms inference, 1.5ms NMS per image at shape (32, 3, 1536, 1536)\n","Results saved to \u001b[1mruns/val/exp48\u001b[0m\n","updating: study_data_mfnets.txt (deflated 75%)\n","Saving study.png...\n"]}]},{"cell_type":"code","source":["!python val.py --task speed --weights /content/yolov5/mfnets.pt --data {dataset.location}/data.yaml --iou 0.3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"deVrymet94yx","executionInfo":{"status":"ok","timestamp":1671597381886,"user_tz":-300,"elapsed":11630,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"}},"outputId":"039e0a71-0f02-4757-8d44-eb56a1581222"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/Uav-7/data.yaml, weights=['/content/yolov5/mfnets.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.3, task=speed, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 13/13 [00:04<00:00,  2.90it/s]\n","                 all        415        876      0.774       0.78      0.813      0.388\n","                bird        415        587      0.805      0.872      0.886      0.407\n","               drone        415        289      0.743      0.689       0.74      0.368\n","Speed: 0.2ms pre-process, 4.0ms inference, 1.1ms NMS per image at shape (32, 3, 640, 640)\n","Results saved to \u001b[1mruns/val/exp13\u001b[0m\n"]}]},{"cell_type":"code","source":["!python val.py --weights /content/yolov5/mfnets.pt --data {dataset.location}/data.yaml --iou 0.3 --img 416 --verbose --save-txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXHAdIDu-HTc","executionInfo":{"status":"ok","timestamp":1671600912290,"user_tz":-300,"elapsed":17015,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"}},"outputId":"d12e82e5-fce2-460a-c91b-865eda7650f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/Uav-7/data.yaml, weights=['/content/yolov5/mfnets.pt'], batch_size=32, imgsz=416, conf_thres=0.001, iou_thres=0.3, task=val, device=, workers=8, single_cls=False, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n","YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","custom_YOLOv5s summary: 232 layers, 2789023 parameters, 0 gradients, 18.9 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels.cache' images and labels... 415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00<?, ?it/s]\n","               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 13/13 [00:06<00:00,  2.03it/s]\n","                 all        415        876        378       44.5      0.909      0.877      0.893      0.899      0.488\n","                bird        415        587        493         75      0.867       0.84      0.853      0.853       0.37\n","               drone        415        289        264         14      0.951      0.913      0.932      0.946      0.605\n","Speed: 0.1ms pre-process, 3.6ms inference, 1.8ms NMS per image at shape (32, 3, 416, 416)\n","Results saved to \u001b[1mruns/val/exp37\u001b[0m\n","415 labels saved to runs/val/exp37/labels\n"]}]},{"cell_type":"code","source":["##I have created a zip file:\n","!zip -r /content/FeatureNet-smal.zip /content/yolov5/runs/\n","##Than I have downloded that zip file:\n","from google.colab import files\n","files.download(\"/content/FeatureNet-smal.zip\")"],"metadata":{"id":"iRYTwQl0euwk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##I have created a zip file:\n","!zip -r /content/detectfeatures.zip /content/yolov5/runs/detect/exp/\n","##Than I have downloded that zip file:\n","from google.colab import files\n","files.download(\"/content/detectfeatures.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TqAEIuZ0N3EQ","executionInfo":{"status":"ok","timestamp":1671601592004,"user_tz":-300,"elapsed":5108,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"}},"outputId":"288fcbe6-f0ee-4ceb-ba48-1385c2a12d4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/yolov5/runs/detect/exp/ (stored 0%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/ (stored 0%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage2_BottleneckCSP_features.png (deflated 0%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage7_Conv_features.png (deflated 33%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage8_SPP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage0_Focus_features.png (deflated 1%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage13_BottleneckCSP_features.png (deflated 15%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage3_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage9_BottleneckCSP_features.png (deflated 33%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage2_BottleneckCSP_features.npy (deflated 9%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage18_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage14_Conv_features.png (deflated 16%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage6_BottleneckCSP_features.png (deflated 15%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage9_BottleneckCSP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage8_SPP_features.png (deflated 34%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage7_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage10_Conv_features.png (deflated 34%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage0_Focus_features.npy (deflated 16%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage16_Concat_features.npy (deflated 30%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage5_Conv_features.png (deflated 15%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage11_Upsample_features.npy (deflated 73%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage4_BottleneckCSP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage1_Conv_features.png (deflated 1%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage15_Upsample_features.png (deflated 16%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage5_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage15_Upsample_features.npy (deflated 74%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage1_Conv_features.npy (deflated 10%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage16_Concat_features.png (deflated 16%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage19_Concat_features.png (deflated 15%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage12_Concat_features.png (deflated 34%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage3_Conv_features.png (deflated 6%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage17_BottleneckCSP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage18_Conv_features.png (deflated 15%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage4_BottleneckCSP_features.png (deflated 6%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage14_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage6_BottleneckCSP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage12_Concat_features.npy (deflated 21%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage11_Upsample_features.png (deflated 34%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage17_BottleneckCSP_features.png (deflated 6%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage13_BottleneckCSP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77/stage10_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/ (stored 0%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage2_BottleneckCSP_features.png (deflated 0%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage22_Concat_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage7_Conv_features.png (deflated 33%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage8_SPP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage0_Focus_features.png (deflated 1%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage13_BottleneckCSP_features.png (deflated 15%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage3_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage9_BottleneckCSP_features.png (deflated 33%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage2_BottleneckCSP_features.npy (deflated 11%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage18_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage14_Conv_features.png (deflated 15%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage6_BottleneckCSP_features.png (deflated 15%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage9_BottleneckCSP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage8_SPP_features.png (deflated 33%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage7_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage20_BottleneckCSP_features.png (deflated 16%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage20_BottleneckCSP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage10_Conv_features.png (deflated 34%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage0_Focus_features.npy (deflated 11%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage16_Concat_features.npy (deflated 30%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage5_Conv_features.png (deflated 15%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage23_BottleneckCSP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage11_Upsample_features.npy (deflated 73%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage4_BottleneckCSP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage1_Conv_features.png (deflated 1%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage15_Upsample_features.png (deflated 15%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage23_BottleneckCSP_features.png (deflated 34%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage22_Concat_features.png (deflated 35%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage5_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage15_Upsample_features.npy (deflated 74%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage1_Conv_features.npy (deflated 10%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage16_Concat_features.png (deflated 15%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage19_Concat_features.png (deflated 14%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage21_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage12_Concat_features.png (deflated 34%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage19_Concat_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage3_Conv_features.png (deflated 6%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage17_BottleneckCSP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage18_Conv_features.png (deflated 14%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage4_BottleneckCSP_features.png (deflated 6%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage21_Conv_features.png (deflated 35%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage14_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage6_BottleneckCSP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage12_Concat_features.npy (deflated 21%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage11_Upsample_features.png (deflated 34%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage17_BottleneckCSP_features.png (deflated 6%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage13_BottleneckCSP_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6/stage10_Conv_features.npy (deflated 8%)\n","  adding: content/yolov5/runs/detect/exp/0046_jpg.rf.2dd8c3d58548003a34f42844ecd0feb6.jpg (deflated 4%)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a93a4a3e-0720-49a9-a713-6b46b2e98bdc\", \"detectfeatures.zip\", 79839483)"]},"metadata":{}}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1ieXUJ2oKG47bilXUZCYgenLvlRksLe0p","timestamp":1667999208418}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}